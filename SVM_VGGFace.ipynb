{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import cPickle\n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import svm\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import caffe\n",
    "import os\n",
    "#from collections import Counter\n",
    "\n",
    "caffe.set_device(0)\n",
    "caffe.set_mode_cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_model_net(model_used):\n",
    "    # Set the right path to your model definition file, pretrained model weights,\n",
    "    # and the image you would like to classify.\n",
    "    MODEL_FILE = '/home/gonzalo/models/VGG_FACE_deploy.prototxt'\n",
    "    PRETRAINED = '/media/gonzalo/OS/mydata/weights_solvers/TO USE/'+model_used\n",
    "    \n",
    "    # load the model\n",
    "    caffe.set_mode_gpu()\n",
    "    caffe.set_device(0)\n",
    "    net = caffe.Classifier(MODEL_FILE, PRETRAINED,\n",
    "                           #mean=np.load('/home/gonzalo/data/MIT/mean_files/7_net_mean.npy').mean(1).mean(1),\n",
    "                           channel_swap=(2,1,0),\n",
    "                           raw_scale=255,\n",
    "                           image_dims=(224, 224))\n",
    "    print \"successfully loaded classifier\"\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function: train_features()\n",
    "# Description:\n",
    "# Input: train_images_filenames, train_labels, extractor, n_images, isPCA=True\n",
    "# Output: D, L\n",
    "def train_features(images_filenames, labels, textractor, n_images, is_pca):\n",
    "\n",
    "    # SIFTdetector = cv2.SIFT(nfeatures=n_Sift_Features)\n",
    "    # read the just 30 train images per class\n",
    "    # extract SIFT keypoints and descriptors\n",
    "    # store descriptors in a python list of numpy arrays\n",
    "\n",
    "    train_descriptors = []\n",
    "    train_label_per_descriptor = []\n",
    "\n",
    "    for i in range(len(images_filenames)):\n",
    "        filename = images_filenames[i]\n",
    "        if train_label_per_descriptor.count(labels[i]) < n_images:\n",
    "            print 'Reading image ' + filename\n",
    "            ima = cv2.imread(filename)\n",
    "            print ima.shape\n",
    "            gray = cv2.cvtColor(ima, cv2.COLOR_BGR2GRAY)\n",
    "            kpt, des = textractor.detectAndCompute(gray, None)\n",
    "            train_descriptors.append(des)\n",
    "            train_label_per_descriptor.append(labels[i])\n",
    "            print str(len(kpt)) + ' extracted keypoints and descriptors'\n",
    "\n",
    "    d = train_descriptors[0]\n",
    "    l = np.array([train_label_per_descriptor[0]] * train_descriptors[0].shape[0])\n",
    "\n",
    "    for i in range(1, len(train_descriptors)):\n",
    "        d = np.vstack((d, train_descriptors[i]))\n",
    "        l = np.hstack((l, np.array([train_label_per_descriptor[i]] * train_descriptors[i].shape[0])))\n",
    "\n",
    "    if is_pca:\n",
    "        print \"Apply PCA algorithm to reduce dimensionality\"\n",
    "        pca.fit(d)\n",
    "        dtrfm = pca.transform(d)\n",
    "    return dtrfm, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function: train_SVM()\n",
    "# Description:\n",
    "# Input: d_scaled, l, kernel_type\n",
    "# Output: clf\n",
    "def train_svm(d_scaled, l, kernel_type):\n",
    "    print 'Training the SVM classifier...'\n",
    "    clf_train = svm.SVC(kernel=kernel_type, C=100).fit(d_scaled, l)\n",
    "    print 'Done!'\n",
    "    return clf_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function: test_classifier()\n",
    "# Description:\n",
    "# Input: images_filenames, labels, extractor, clf, stdSlr, pca, isPCA=True\n",
    "# Output: numcorrect\n",
    "def classifier(images_filenames, labels, cextractor, cclf, cstdslr, is_pca, cpca,):\n",
    "    numtestimages = 0\n",
    "    cnumcorrect = 0\n",
    "    for i in range(len(images_filenames)):\n",
    "        filename = images_filenames[i]\n",
    "        ima = cv2.imread(filename)\n",
    "        gray = cv2.cvtColor(ima, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        kpt, des = cextractor.detectAndCompute(gray, None)\n",
    "        if is_pca:\n",
    "            dtrfm = cpca.transform(des)\n",
    "\n",
    "        predictions = cclf.predict(cstdslr.transform(des))\n",
    "        values, counts = np.unique(predictions, return_counts=True)\n",
    "        predictedclass = values[np.argmax(counts)]\n",
    "        print 'image ' + filename + ' was from class ' + labels[i] + ' and was predicted ' + predictedclass\n",
    "        numtestimages += 1\n",
    "        if predictedclass == labels[i]:\n",
    "            cnumcorrect += 1\n",
    "    return cnumcorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rewrite_list(train_set_list,test_set_list):\n",
    "    list_of_files, list_of_labels =[],[]\n",
    "    with open(train_set_list,'r') as f, open('/home/gonzalo/data/MIT/train_0.dat','w') as g, open('/home/gonzalo/data/MIT/train_0_labels.dat','w') as h:\n",
    "        for x in f:\n",
    "            x = x.rstrip()\n",
    "            if not x: continue\n",
    "            filename, label = x.split( )\n",
    "            filename = str('/home/gonzalo/data/MIT/train/'+ filename)\n",
    "            list_of_files.append(filename), list_of_labels.append(label)\n",
    "        cPickle.dump(list_of_files, g)\n",
    "        cPickle.dump(list_of_labels, h)\n",
    "            \n",
    "    list_of_files, list_of_labels =[],[]        \n",
    "    with open(test_set_list,'r') as i, open('/home/gonzalo/data/MIT/test_0.dat','w') as j, open('/home/gonzalo/data/MIT/test_0_labels.dat','w') as k:\n",
    "        for x in i:\n",
    "            x = x.rstrip()\n",
    "            if not x: continue\n",
    "            filename, label = x.split( )\n",
    "            filename = str('/home/gonzalo/data/MIT/test/'+ filename)\n",
    "            list_of_files.append(filename), list_of_labels.append(label)\n",
    "        cPickle.dump(list_of_files, j)\n",
    "        cPickle.dump(list_of_labels, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ Main function ------------------ #\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    rewrite_list('/home/gonzalo/data/MIT/train_0.txt','/home/gonzalo/data/MIT/test_0.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully loaded classifier\n",
      "2020 250\n"
     ]
    }
   ],
   "source": [
    "    model_used = 'VGG_FACE.caffemodel'\n",
    "    net = load_model_net(model_used)\n",
    "\n",
    "    # Start timer to analyse performance\n",
    "    start = time.time()\n",
    "\n",
    "    # Read the train and test files\n",
    "    train_images_filenames = cPickle.load(open('/home/gonzalo/data/MIT/train_0.dat', 'r'))\n",
    "    test_images_filenames = cPickle.load(open('/home/gonzalo/data/MIT/test_0.dat', 'r'))\n",
    "    \n",
    "    print len(train_images_filenames), len(test_images_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2020 training images filenames with classes  set(['0004', '0005', '0006', '0007', '0000', '0001', '0002', '0003', '0008', '0009'])\n",
      "Loaded 250 testing images filenames with classes  set(['0004', '0005', '0006', '0007', '0000', '0001', '0002', '0003', '0008', '0009'])\n",
      "Reading image /home/gonzalo/data/MIT/train/train_0/0000/0000_-12_0_0_15_15_1fr.jpg\n",
      "(227, 227, 3)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Classifier' object has no attribute 'detectAndCompute'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-a52452d88aa9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mnum_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mapply_pca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images_filenames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextractor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_pca\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Train a linear SVM classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-6a9c6f6bf1cd>\u001b[0m in \u001b[0;36mtrain_features\u001b[0;34m(images_filenames, labels, textractor, n_images, is_pca)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0mima\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mima\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mkpt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtextractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetectAndCompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0mtrain_descriptors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mtrain_label_per_descriptor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Classifier' object has no attribute 'detectAndCompute'"
     ]
    }
   ],
   "source": [
    "    train_labels = cPickle.load(open('/home/gonzalo/data/MIT/train_0_labels.dat', 'r'))\n",
    "    test_labels = cPickle.load(open('/home/gonzalo/data/MIT/test_0_labels.dat', 'r'))\n",
    "\n",
    "    print 'Loaded ' + str(len(train_images_filenames)) + ' training images filenames with classes ', set(train_labels)\n",
    "    print 'Loaded ' + str(len(test_images_filenames)) + ' testing images filenames with classes ', set(test_labels)\n",
    "\n",
    "    # PCA components\n",
    "    pca = PCA(n_components=20)\n",
    "\n",
    "    # Create the SIFT detector object\n",
    "    extractor = net#cv2.SIFT(nfeatures=100)\n",
    "\n",
    "    # Create the SURF detector object\n",
    "    # extractor = cv2.SURF(nfeaures = 100)\n",
    "\n",
    "    num_images = 15\n",
    "    apply_pca = False\n",
    "    D, L = train_features(train_images_filenames, train_labels, extractor, num_images, apply_pca)\n",
    "\n",
    "    # Train a linear SVM classifier\n",
    "    stdSlr = StandardScaler().fit(D)\n",
    "    D_scaled = stdSlr.transform(D)\n",
    "\n",
    "    kernel = 'linear'\n",
    "    clf = train_svm(D_scaled, L, kernel)\n",
    "\n",
    "    print 'Classifier trained'\n",
    "\n",
    "    # Get all the test data and predict their labels\n",
    "    numcorrect = classifier(test_images_filenames, test_labels, extractor, clf, stdSlr, True, pca)\n",
    "\n",
    "    print 'Final accuracy: ' + str(numcorrect * 100.0 / len(test_images_filenames))\n",
    "\n",
    "    # End timer to print time spent\n",
    "    end = time.time()\n",
    "    print 'Done in ' + str(end - start) + ' secs.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
